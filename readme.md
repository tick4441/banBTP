This is the dataset for BanBTP, It's quite small!

the brain.txt DATASET is licensed under BSDCLAUSE 3 and is 100 percent open-source.

Any data listed on other repos are always checked to see in public domain. if not in public domain, it is not used. All data in the large version of the dataset is public open source datasets from sources like huggingface, kaggle, and other open source dataset communities.

All data in the repo is enough to build a basic 124M SLM.

BanBTP's goal is to be a fully functional, fully open-source data and model LLM and SLM designed to run on any hardware. 

BanBTP is designed to be easy, light and good on any hardware. 900MB RAM required

The dataset amd models are licensed under BSD clause 3.

This is probably one of the very few fully open-source and not just open-weight SLM!

when training the model, it is best to set it at 3-4 epochs. 1 epoch may not do much.

This LLM is fully open. you may redistribute or do whatever with the model.

This LLM may be innaccurate in stuff, but this is because it is very small.

When loading the model for inference, you may give it a prompt and test it out! The 124M varient is best for very small computers, but the 700+M varient is a finetuned dialogpt with BanBTP's small dataset. the 700+M varient was just a testing finetuned version,but will stay up since it is really good at conversation and reasoning. though it is licensed under the same license as dialogpt, so you'll have to see dialogpt for more info on if it is open or not. (I'm pretty sure dialogpt is closed source in the dataset but is open-weight for the model.) 

Enjoy BanBTP!

Rock on :D

NOTE: BanBTP is provided in GGUF format, not huggingface format. this is to make the model easy to use and distribute.
